{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from sklearn import model_selection\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Padronização\\nmin_values = X.min(axis=0)\\nmax_values = X.max(axis=0)\\nX = (X - min_values) / (max_values - min_values)'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def padronizar_normal(matriz_X):\n",
    "    for i in range(np.shape(matriz_X)[1]):\n",
    "        matriz_X[:,i] = (matriz_X[:,i] - np.mean(matriz_X[:,i]))/np.std(matriz_X[:,i]) # X menos media/desvio padrao\n",
    "\n",
    "    return matriz_X\n",
    "\n",
    "\"\"\"# Padronização\n",
    "min_values = X.min(axis=0)\n",
    "max_values = X.max(axis=0)\n",
    "X = (X - min_values) / (max_values - min_values)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Reconhecimento-de-digitos-ML-2023.2/Projeto 2.1/creditcard.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n",
      "Class\n",
      "1    492\n",
      "0    492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Retirando a coluna de tempo\n",
    "data = data.drop('Time', axis=1)\n",
    "print(data['Class'].value_counts())\n",
    "# Eu possuo 284315 valores de classe 0 e 492 valores de classe 1. Deixe os valores iguais\n",
    "data = data.sample(frac=1)\n",
    "fraude = data.loc[data['Class'] == 1]\n",
    "nao_fraude = data.loc[data['Class'] == 0][:492]\n",
    "normal_distributed_data = pd.concat([fraude, nao_fraude])\n",
    "print(normal_distributed_data['Class'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(normal_distributed_data.drop('Class', axis=1))\n",
    "Y = np.array(normal_distributed_data['Class'])\n",
    "RANDOM_STATE = 2\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Normalizando os dados\n",
    "X = padronizar_normal(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (629, 29)\n",
      "Y_train: (629,)\n",
      "X_val: (158, 29)\n",
      "Y_val: (158,)\n"
     ]
    }
   ],
   "source": [
    "# Separando em dados de treino, teste e validação\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "X_train, X_val, Y_train, Y_val = model_selection.train_test_split(X_train, Y_train, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('Y_train:', Y_train.shape)\n",
    "print('X_val:', X_val.shape)\n",
    "print('Y_val:', Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9967741935483871"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encontrando o número de neurônios na camada escondida\n",
    "num_neuronios = (X_train.shape[0] - 10)/(10*(X_train.shape[1] + 2))\n",
    "num_neuronios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bergs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Criando a rede neural\n",
    "model = Sequential()\n",
    "# Adicionando neurônios em uma camada oculta\n",
    "model.add(Dense(2, input_dim=29, kernel_initializer='normal', activation='tanh')) #quantidade de neuronios na camada escondida, nº de features\n",
    "\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid')) #camada de saída\n",
    "\n",
    "# adicionando a taxa de aprendizado\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8470 - loss: 0.6827 - val_accuracy: 0.8038 - val_loss: 0.6783\n",
      "Epoch 2/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8581 - loss: 0.6727 - val_accuracy: 0.8354 - val_loss: 0.6650\n",
      "Epoch 3/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8724 - loss: 0.6558 - val_accuracy: 0.8228 - val_loss: 0.6491\n",
      "Epoch 4/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8695 - loss: 0.6395 - val_accuracy: 0.8354 - val_loss: 0.6325\n",
      "Epoch 5/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8862 - loss: 0.6179 - val_accuracy: 0.8418 - val_loss: 0.6161\n",
      "Epoch 6/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8774 - loss: 0.6027 - val_accuracy: 0.8544 - val_loss: 0.6006\n",
      "Epoch 7/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8810 - loss: 0.5877 - val_accuracy: 0.8608 - val_loss: 0.5859\n",
      "Epoch 8/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8754 - loss: 0.5725 - val_accuracy: 0.8671 - val_loss: 0.5718\n",
      "Epoch 9/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8671 - loss: 0.5588 - val_accuracy: 0.8671 - val_loss: 0.5585\n",
      "Epoch 10/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8997 - loss: 0.5390 - val_accuracy: 0.8734 - val_loss: 0.5457\n",
      "Epoch 11/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8981 - loss: 0.5270 - val_accuracy: 0.8734 - val_loss: 0.5334\n",
      "Epoch 12/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8797 - loss: 0.5192 - val_accuracy: 0.8734 - val_loss: 0.5219\n",
      "Epoch 13/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9046 - loss: 0.5000 - val_accuracy: 0.8734 - val_loss: 0.5104\n",
      "Epoch 14/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8974 - loss: 0.4914 - val_accuracy: 0.8734 - val_loss: 0.4994\n",
      "Epoch 15/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8991 - loss: 0.4794 - val_accuracy: 0.8734 - val_loss: 0.4890\n",
      "Epoch 16/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 0.4590 - val_accuracy: 0.8924 - val_loss: 0.4787\n",
      "Epoch 17/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9065 - loss: 0.4552 - val_accuracy: 0.9051 - val_loss: 0.4690\n",
      "Epoch 18/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9075 - loss: 0.4497 - val_accuracy: 0.9051 - val_loss: 0.4595\n",
      "Epoch 19/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8951 - loss: 0.4487 - val_accuracy: 0.9051 - val_loss: 0.4501\n",
      "Epoch 20/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8830 - loss: 0.4443 - val_accuracy: 0.9051 - val_loss: 0.4409\n",
      "Epoch 21/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9225 - loss: 0.4141 - val_accuracy: 0.9051 - val_loss: 0.4320\n",
      "Epoch 22/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9044 - loss: 0.4135 - val_accuracy: 0.9051 - val_loss: 0.4235\n",
      "Epoch 23/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9020 - loss: 0.4089 - val_accuracy: 0.9051 - val_loss: 0.4149\n",
      "Epoch 24/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8957 - loss: 0.4114 - val_accuracy: 0.9051 - val_loss: 0.4065\n",
      "Epoch 25/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9104 - loss: 0.3943 - val_accuracy: 0.9051 - val_loss: 0.3984\n",
      "Epoch 26/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.3741 - val_accuracy: 0.9051 - val_loss: 0.3904\n",
      "Epoch 27/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9077 - loss: 0.3809 - val_accuracy: 0.9114 - val_loss: 0.3827\n",
      "Epoch 28/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9176 - loss: 0.3698 - val_accuracy: 0.9114 - val_loss: 0.3751\n",
      "Epoch 29/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9119 - loss: 0.3677 - val_accuracy: 0.9177 - val_loss: 0.3678\n",
      "Epoch 30/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9090 - loss: 0.3618 - val_accuracy: 0.9241 - val_loss: 0.3608\n",
      "Epoch 31/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9049 - loss: 0.3564 - val_accuracy: 0.9241 - val_loss: 0.3542\n",
      "Epoch 32/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9206 - loss: 0.3377 - val_accuracy: 0.9304 - val_loss: 0.3471\n",
      "Epoch 33/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9193 - loss: 0.3406 - val_accuracy: 0.9304 - val_loss: 0.3408\n",
      "Epoch 34/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9280 - loss: 0.3259 - val_accuracy: 0.9304 - val_loss: 0.3345\n",
      "Epoch 35/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9246 - loss: 0.3265 - val_accuracy: 0.9367 - val_loss: 0.3286\n",
      "Epoch 36/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9369 - loss: 0.3127 - val_accuracy: 0.9367 - val_loss: 0.3227\n",
      "Epoch 37/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9317 - loss: 0.3135 - val_accuracy: 0.9367 - val_loss: 0.3170\n",
      "Epoch 38/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9389 - loss: 0.2978 - val_accuracy: 0.9367 - val_loss: 0.3114\n",
      "Epoch 39/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9336 - loss: 0.3099 - val_accuracy: 0.9367 - val_loss: 0.3064\n",
      "Epoch 40/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9297 - loss: 0.3016 - val_accuracy: 0.9367 - val_loss: 0.3013\n",
      "Epoch 41/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9452 - loss: 0.2858 - val_accuracy: 0.9367 - val_loss: 0.2966\n",
      "Epoch 42/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9242 - loss: 0.2974 - val_accuracy: 0.9430 - val_loss: 0.2917\n",
      "Epoch 43/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9372 - loss: 0.2840 - val_accuracy: 0.9430 - val_loss: 0.2872\n",
      "Epoch 44/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9403 - loss: 0.2793 - val_accuracy: 0.9430 - val_loss: 0.2827\n",
      "Epoch 45/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9467 - loss: 0.2619 - val_accuracy: 0.9430 - val_loss: 0.2782\n",
      "Epoch 46/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9124 - loss: 0.2944 - val_accuracy: 0.9494 - val_loss: 0.2744\n",
      "Epoch 47/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.2612 - val_accuracy: 0.9494 - val_loss: 0.2704\n",
      "Epoch 48/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9334 - loss: 0.2670 - val_accuracy: 0.9494 - val_loss: 0.2668\n",
      "Epoch 49/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9345 - loss: 0.2587 - val_accuracy: 0.9430 - val_loss: 0.2630\n",
      "Epoch 50/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9527 - loss: 0.2414 - val_accuracy: 0.9430 - val_loss: 0.2594\n",
      "Epoch 51/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.2500 - val_accuracy: 0.9430 - val_loss: 0.2563\n",
      "Epoch 52/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9477 - loss: 0.2399 - val_accuracy: 0.9430 - val_loss: 0.2529\n",
      "Epoch 53/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9480 - loss: 0.2354 - val_accuracy: 0.9430 - val_loss: 0.2499\n",
      "Epoch 54/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9455 - loss: 0.2356 - val_accuracy: 0.9430 - val_loss: 0.2467\n",
      "Epoch 55/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9394 - loss: 0.2341 - val_accuracy: 0.9430 - val_loss: 0.2443\n",
      "Epoch 56/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9432 - loss: 0.2361 - val_accuracy: 0.9430 - val_loss: 0.2412\n",
      "Epoch 57/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9415 - loss: 0.2370 - val_accuracy: 0.9430 - val_loss: 0.2382\n",
      "Epoch 58/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9167 - loss: 0.2554 - val_accuracy: 0.9430 - val_loss: 0.2359\n",
      "Epoch 59/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9457 - loss: 0.2240 - val_accuracy: 0.9430 - val_loss: 0.2335\n",
      "Epoch 60/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9495 - loss: 0.2109 - val_accuracy: 0.9430 - val_loss: 0.2310\n",
      "Epoch 61/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9332 - loss: 0.2340 - val_accuracy: 0.9430 - val_loss: 0.2285\n",
      "Epoch 62/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9483 - loss: 0.2160 - val_accuracy: 0.9430 - val_loss: 0.2261\n",
      "Epoch 63/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9386 - loss: 0.2141 - val_accuracy: 0.9430 - val_loss: 0.2239\n",
      "Epoch 64/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.2017 - val_accuracy: 0.9430 - val_loss: 0.2221\n",
      "Epoch 65/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9511 - loss: 0.1995 - val_accuracy: 0.9430 - val_loss: 0.2198\n",
      "Epoch 66/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9518 - loss: 0.2002 - val_accuracy: 0.9430 - val_loss: 0.2176\n",
      "Epoch 67/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9283 - loss: 0.2223 - val_accuracy: 0.9430 - val_loss: 0.2161\n",
      "Epoch 68/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9523 - loss: 0.2030 - val_accuracy: 0.9430 - val_loss: 0.2140\n",
      "Epoch 69/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9468 - loss: 0.1959 - val_accuracy: 0.9430 - val_loss: 0.2125\n",
      "Epoch 70/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9502 - loss: 0.1964 - val_accuracy: 0.9430 - val_loss: 0.2107\n",
      "Epoch 71/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.1974 - val_accuracy: 0.9430 - val_loss: 0.2088\n",
      "Epoch 72/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9532 - loss: 0.1824 - val_accuracy: 0.9367 - val_loss: 0.2072\n",
      "Epoch 73/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9511 - loss: 0.1953 - val_accuracy: 0.9430 - val_loss: 0.2054\n",
      "Epoch 74/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9584 - loss: 0.1827 - val_accuracy: 0.9430 - val_loss: 0.2038\n",
      "Epoch 75/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 0.2094 - val_accuracy: 0.9367 - val_loss: 0.2025\n",
      "Epoch 76/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9464 - loss: 0.1957 - val_accuracy: 0.9367 - val_loss: 0.2009\n",
      "Epoch 77/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9400 - loss: 0.1991 - val_accuracy: 0.9367 - val_loss: 0.1995\n",
      "Epoch 78/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9490 - loss: 0.1953 - val_accuracy: 0.9367 - val_loss: 0.1983\n",
      "Epoch 79/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9446 - loss: 0.1997 - val_accuracy: 0.9367 - val_loss: 0.1967\n",
      "Epoch 80/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9503 - loss: 0.1832 - val_accuracy: 0.9367 - val_loss: 0.1957\n",
      "Epoch 81/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9565 - loss: 0.1727 - val_accuracy: 0.9367 - val_loss: 0.1942\n",
      "Epoch 82/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9468 - loss: 0.1961 - val_accuracy: 0.9367 - val_loss: 0.1929\n",
      "Epoch 83/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9496 - loss: 0.1880 - val_accuracy: 0.9367 - val_loss: 0.1920\n",
      "Epoch 84/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1754 - val_accuracy: 0.9367 - val_loss: 0.1909\n",
      "Epoch 85/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9594 - loss: 0.1721 - val_accuracy: 0.9367 - val_loss: 0.1901\n",
      "Epoch 86/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9387 - loss: 0.2075 - val_accuracy: 0.9367 - val_loss: 0.1889\n",
      "Epoch 87/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9450 - loss: 0.1882 - val_accuracy: 0.9367 - val_loss: 0.1876\n",
      "Epoch 88/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9630 - loss: 0.1567 - val_accuracy: 0.9367 - val_loss: 0.1867\n",
      "Epoch 89/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9505 - loss: 0.1798 - val_accuracy: 0.9367 - val_loss: 0.1861\n",
      "Epoch 90/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9429 - loss: 0.1912 - val_accuracy: 0.9367 - val_loss: 0.1848\n",
      "Epoch 91/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9478 - loss: 0.1803 - val_accuracy: 0.9430 - val_loss: 0.1839\n",
      "Epoch 92/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9568 - loss: 0.1697 - val_accuracy: 0.9430 - val_loss: 0.1833\n",
      "Epoch 93/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9484 - loss: 0.1775 - val_accuracy: 0.9367 - val_loss: 0.1822\n",
      "Epoch 94/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9424 - loss: 0.1869 - val_accuracy: 0.9430 - val_loss: 0.1814\n",
      "Epoch 95/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9588 - loss: 0.1642 - val_accuracy: 0.9430 - val_loss: 0.1804\n",
      "Epoch 96/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9446 - loss: 0.1805 - val_accuracy: 0.9430 - val_loss: 0.1794\n",
      "Epoch 97/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.1923 - val_accuracy: 0.9430 - val_loss: 0.1791\n",
      "Epoch 98/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.1455 - val_accuracy: 0.9430 - val_loss: 0.1782\n",
      "Epoch 99/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.1594 - val_accuracy: 0.9430 - val_loss: 0.1774\n",
      "Epoch 100/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.1760 - val_accuracy: 0.9430 - val_loss: 0.1768\n",
      "Epoch 101/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9677 - loss: 0.1442 - val_accuracy: 0.9430 - val_loss: 0.1760\n",
      "Epoch 102/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9506 - loss: 0.1680 - val_accuracy: 0.9430 - val_loss: 0.1755\n",
      "Epoch 103/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1674 - val_accuracy: 0.9430 - val_loss: 0.1749\n",
      "Epoch 104/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9557 - loss: 0.1611 - val_accuracy: 0.9430 - val_loss: 0.1740\n",
      "Epoch 105/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1591 - val_accuracy: 0.9430 - val_loss: 0.1735\n",
      "Epoch 106/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.1455 - val_accuracy: 0.9430 - val_loss: 0.1730\n",
      "Epoch 107/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9551 - loss: 0.1731 - val_accuracy: 0.9430 - val_loss: 0.1726\n",
      "Epoch 108/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9527 - loss: 0.1731 - val_accuracy: 0.9430 - val_loss: 0.1719\n",
      "Epoch 109/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.1455 - val_accuracy: 0.9430 - val_loss: 0.1712\n",
      "Epoch 110/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9499 - loss: 0.1766 - val_accuracy: 0.9430 - val_loss: 0.1706\n",
      "Epoch 111/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.1697 - val_accuracy: 0.9430 - val_loss: 0.1701\n",
      "Epoch 112/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9423 - loss: 0.1829 - val_accuracy: 0.9430 - val_loss: 0.1696\n",
      "Epoch 113/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1495 - val_accuracy: 0.9430 - val_loss: 0.1691\n",
      "Epoch 114/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.1386 - val_accuracy: 0.9430 - val_loss: 0.1685\n",
      "Epoch 115/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9529 - loss: 0.1605 - val_accuracy: 0.9430 - val_loss: 0.1681\n",
      "Epoch 116/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1575 - val_accuracy: 0.9430 - val_loss: 0.1679\n",
      "Epoch 117/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9548 - loss: 0.1625 - val_accuracy: 0.9430 - val_loss: 0.1674\n",
      "Epoch 118/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9554 - loss: 0.1654 - val_accuracy: 0.9430 - val_loss: 0.1671\n",
      "Epoch 119/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.1393 - val_accuracy: 0.9430 - val_loss: 0.1663\n",
      "Epoch 120/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9496 - loss: 0.1712 - val_accuracy: 0.9430 - val_loss: 0.1659\n",
      "Epoch 121/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9505 - loss: 0.1644 - val_accuracy: 0.9430 - val_loss: 0.1656\n",
      "Epoch 122/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1557 - val_accuracy: 0.9430 - val_loss: 0.1653\n",
      "Epoch 123/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.1378 - val_accuracy: 0.9430 - val_loss: 0.1647\n",
      "Epoch 124/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1451 - val_accuracy: 0.9430 - val_loss: 0.1644\n",
      "Epoch 125/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.1556 - val_accuracy: 0.9430 - val_loss: 0.1638\n",
      "Epoch 126/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9420 - loss: 0.1790 - val_accuracy: 0.9430 - val_loss: 0.1636\n",
      "Epoch 127/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9584 - loss: 0.1364 - val_accuracy: 0.9430 - val_loss: 0.1633\n",
      "Epoch 128/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1659 - val_accuracy: 0.9430 - val_loss: 0.1629\n",
      "Epoch 129/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1493 - val_accuracy: 0.9430 - val_loss: 0.1628\n",
      "Epoch 130/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9526 - loss: 0.1649 - val_accuracy: 0.9430 - val_loss: 0.1626\n",
      "Epoch 131/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9527 - loss: 0.1675 - val_accuracy: 0.9430 - val_loss: 0.1620\n",
      "Epoch 132/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9613 - loss: 0.1448 - val_accuracy: 0.9430 - val_loss: 0.1620\n",
      "Epoch 133/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9547 - loss: 0.1667 - val_accuracy: 0.9430 - val_loss: 0.1615\n",
      "Epoch 134/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9636 - loss: 0.1497 - val_accuracy: 0.9430 - val_loss: 0.1611\n",
      "Epoch 135/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9494 - loss: 0.1627 - val_accuracy: 0.9494 - val_loss: 0.1607\n",
      "Epoch 136/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9627 - loss: 0.1323 - val_accuracy: 0.9430 - val_loss: 0.1602\n",
      "Epoch 137/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1523 - val_accuracy: 0.9430 - val_loss: 0.1600\n",
      "Epoch 138/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9480 - loss: 0.1741 - val_accuracy: 0.9430 - val_loss: 0.1598\n",
      "Epoch 139/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9525 - loss: 0.1625 - val_accuracy: 0.9430 - val_loss: 0.1596\n",
      "Epoch 140/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9596 - loss: 0.1499 - val_accuracy: 0.9430 - val_loss: 0.1595\n",
      "Epoch 141/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1383 - val_accuracy: 0.9494 - val_loss: 0.1594\n",
      "Epoch 142/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9684 - loss: 0.1211 - val_accuracy: 0.9430 - val_loss: 0.1589\n",
      "Epoch 143/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9552 - loss: 0.1486 - val_accuracy: 0.9494 - val_loss: 0.1587\n",
      "Epoch 144/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9579 - loss: 0.1480 - val_accuracy: 0.9494 - val_loss: 0.1585\n",
      "Epoch 145/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9541 - loss: 0.1634 - val_accuracy: 0.9430 - val_loss: 0.1585\n",
      "Epoch 146/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9579 - loss: 0.1486 - val_accuracy: 0.9494 - val_loss: 0.1581\n",
      "Epoch 147/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9599 - loss: 0.1428 - val_accuracy: 0.9494 - val_loss: 0.1578\n",
      "Epoch 148/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9480 - loss: 0.1773 - val_accuracy: 0.9494 - val_loss: 0.1577\n",
      "Epoch 149/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.1326 - val_accuracy: 0.9430 - val_loss: 0.1578\n",
      "Epoch 150/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.1406 - val_accuracy: 0.9494 - val_loss: 0.1573\n"
     ]
    }
   ],
   "source": [
    "#Treinando a rede neural\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=150, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step  \n",
      "\n",
      "--> Acuracia (treino): 0.9571\n",
      "--> Acuracia (validacao): 0.9494\n",
      "--> acc_train - acc_val = 0.0077\n",
      "Agora a validação:\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Metrica de erro')\n",
    "plt.ylabel('Erro')\n",
    "plt.xlabel('Epoca')\n",
    "plt.legend(['Treinamento'])\n",
    "plt.show()\n",
    "\n",
    "# Obtendo a acuracia usando accuracy_score()\n",
    "pred = np.round(model.predict(X_train))\n",
    "acc_train = accuracy_score(Y_train, pred)\n",
    "\n",
    "pred_val = np.round(model.predict(X_val))\n",
    "acc_val = accuracy_score(Y_val, pred_val)\n",
    "\n",
    "print(f'\\n--> Acuracia (treino): {acc_train:.4f}')\n",
    "print(f'--> Acuracia (validacao): {acc_val:.4f}')\n",
    "print(f\"--> acc_train - acc_val = {acc_train - acc_val:.4f}\")\n",
    "pred_np = np.array(pred)\n",
    "# encontrando os valores unicos de pred_np\n",
    "unique, counts = np.unique(pred_np, return_counts=True)\n",
    "dict(zip(unique, counts))\n",
    "# exibindo esses valores unicos\n",
    "print('Agora a validação:')\n",
    "print(pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., 82.],\n",
       "       [ 1., 76.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#descobrindo quantos valores unicos existem em pred_val\n",
    "valores, contagens = np.unique(pred_val, return_counts=True)\n",
    "\n",
    "# Combina os valores únicos e as contagens correspondentes\n",
    "resultados = np.column_stack((valores, contagens))\n",
    "\n",
    "resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 78],\n",
       "       [ 1, 80]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valores, contagens = np.unique(Y_val, return_counts=True)\n",
    "resultados = np.column_stack((valores, contagens))\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
