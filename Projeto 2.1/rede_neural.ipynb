{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from sklearn import model_selection\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padronizar_normal(matriz_X):\n",
    "    for i in range(np.shape(matriz_X)[1]):\n",
    "        matriz_X[:,i] = (matriz_X[:,i] - np.mean(matriz_X[:,i]))/np.std(matriz_X[:,i]) # X menos media/desvio padrao\n",
    "\n",
    "    return matriz_X\n",
    "\n",
    "def normalizar(X):\n",
    "    min_values = X.min(axis=0)\n",
    "    max_values = X.max(axis=0)\n",
    "    X = (X - min_values) / (max_values - min_values)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões do dataframe:  (284807, 31)\n",
      "Quantidades de cada classe: Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"dataframe_original = pd.read_csv('creditcard.csv')\n",
    "print(\"Dimensões do dataframe: \",dataframe_original.shape)\n",
    "print(\"Quantidades de cada classe:\", dataframe_original['Class'].value_counts())\n",
    "# Reduzindo a quantidade de amostras para 10000 da classe 0 e todas da classe 1\n",
    "dataframe_original = dataframe_original.sample(frac=1) # embaralhando as amostras\n",
    "fraude = dataframe_original.loc[dataframe_original['Class'] == 1]\n",
    "nao_fraude = dataframe_original.loc[dataframe_original['Class'] == 0][:10000]\n",
    "dataframe_reduzido = pd.concat([fraude, nao_fraude])\n",
    "dataframe_reduzido.to_csv('creditcard_reduced.csv', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62080.0</td>\n",
       "      <td>-1.599457</td>\n",
       "      <td>2.607720</td>\n",
       "      <td>-2.987193</td>\n",
       "      <td>3.064156</td>\n",
       "      <td>-2.497914</td>\n",
       "      <td>-0.541103</td>\n",
       "      <td>-2.277786</td>\n",
       "      <td>1.268166</td>\n",
       "      <td>-1.997331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662933</td>\n",
       "      <td>0.184087</td>\n",
       "      <td>-0.089452</td>\n",
       "      <td>-0.506000</td>\n",
       "      <td>-0.062259</td>\n",
       "      <td>-0.052714</td>\n",
       "      <td>0.322854</td>\n",
       "      <td>0.135268</td>\n",
       "      <td>180.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>149096.0</td>\n",
       "      <td>1.184891</td>\n",
       "      <td>3.152084</td>\n",
       "      <td>-6.134780</td>\n",
       "      <td>5.531252</td>\n",
       "      <td>1.733867</td>\n",
       "      <td>-1.816861</td>\n",
       "      <td>-0.916696</td>\n",
       "      <td>0.265568</td>\n",
       "      <td>-3.158014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124236</td>\n",
       "      <td>-0.823865</td>\n",
       "      <td>-0.079887</td>\n",
       "      <td>0.028828</td>\n",
       "      <td>0.389711</td>\n",
       "      <td>0.060171</td>\n",
       "      <td>0.485187</td>\n",
       "      <td>0.326552</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93860.0</td>\n",
       "      <td>-10.632375</td>\n",
       "      <td>7.251936</td>\n",
       "      <td>-17.681072</td>\n",
       "      <td>8.204144</td>\n",
       "      <td>-10.166591</td>\n",
       "      <td>-4.510344</td>\n",
       "      <td>-12.981606</td>\n",
       "      <td>6.783589</td>\n",
       "      <td>-4.659330</td>\n",
       "      <td>...</td>\n",
       "      <td>2.715357</td>\n",
       "      <td>0.695603</td>\n",
       "      <td>-1.138122</td>\n",
       "      <td>0.459442</td>\n",
       "      <td>0.386337</td>\n",
       "      <td>0.522438</td>\n",
       "      <td>-1.416604</td>\n",
       "      <td>-0.488307</td>\n",
       "      <td>188.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102622.0</td>\n",
       "      <td>-2.877176</td>\n",
       "      <td>4.569649</td>\n",
       "      <td>-9.553069</td>\n",
       "      <td>4.441079</td>\n",
       "      <td>-3.653961</td>\n",
       "      <td>-1.877981</td>\n",
       "      <td>-3.514353</td>\n",
       "      <td>1.547608</td>\n",
       "      <td>-2.503304</td>\n",
       "      <td>...</td>\n",
       "      <td>1.272896</td>\n",
       "      <td>1.300268</td>\n",
       "      <td>-0.003950</td>\n",
       "      <td>-0.360848</td>\n",
       "      <td>-0.597526</td>\n",
       "      <td>-0.390901</td>\n",
       "      <td>0.592197</td>\n",
       "      <td>-0.241010</td>\n",
       "      <td>346.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10487</th>\n",
       "      <td>29135.0</td>\n",
       "      <td>1.148470</td>\n",
       "      <td>-0.226385</td>\n",
       "      <td>-1.378984</td>\n",
       "      <td>-0.501250</td>\n",
       "      <td>2.115918</td>\n",
       "      <td>3.156576</td>\n",
       "      <td>-0.191150</td>\n",
       "      <td>0.725852</td>\n",
       "      <td>-0.240172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.497682</td>\n",
       "      <td>-1.855851</td>\n",
       "      <td>0.146490</td>\n",
       "      <td>0.960612</td>\n",
       "      <td>0.220649</td>\n",
       "      <td>-0.123232</td>\n",
       "      <td>-0.058349</td>\n",
       "      <td>0.027293</td>\n",
       "      <td>94.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10488</th>\n",
       "      <td>161456.0</td>\n",
       "      <td>0.098372</td>\n",
       "      <td>0.881126</td>\n",
       "      <td>-0.412761</td>\n",
       "      <td>-0.501913</td>\n",
       "      <td>0.817211</td>\n",
       "      <td>-0.925919</td>\n",
       "      <td>0.864430</td>\n",
       "      <td>-0.038913</td>\n",
       "      <td>0.142891</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.346648</td>\n",
       "      <td>-0.932954</td>\n",
       "      <td>0.134695</td>\n",
       "      <td>0.594512</td>\n",
       "      <td>-0.465915</td>\n",
       "      <td>0.113468</td>\n",
       "      <td>0.211053</td>\n",
       "      <td>0.083482</td>\n",
       "      <td>6.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10489</th>\n",
       "      <td>20259.0</td>\n",
       "      <td>-0.230903</td>\n",
       "      <td>0.188957</td>\n",
       "      <td>1.950648</td>\n",
       "      <td>-1.682032</td>\n",
       "      <td>-0.491241</td>\n",
       "      <td>0.442542</td>\n",
       "      <td>-0.611728</td>\n",
       "      <td>-0.566704</td>\n",
       "      <td>2.466857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.615393</td>\n",
       "      <td>-0.317370</td>\n",
       "      <td>-0.344081</td>\n",
       "      <td>-0.355076</td>\n",
       "      <td>1.492861</td>\n",
       "      <td>-0.662246</td>\n",
       "      <td>0.117670</td>\n",
       "      <td>0.129243</td>\n",
       "      <td>11.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10490</th>\n",
       "      <td>32140.0</td>\n",
       "      <td>-0.818437</td>\n",
       "      <td>0.592785</td>\n",
       "      <td>0.468012</td>\n",
       "      <td>-0.279240</td>\n",
       "      <td>1.401790</td>\n",
       "      <td>-1.316362</td>\n",
       "      <td>0.647986</td>\n",
       "      <td>-0.015513</td>\n",
       "      <td>-0.784337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056923</td>\n",
       "      <td>-0.071114</td>\n",
       "      <td>-0.134238</td>\n",
       "      <td>-0.112990</td>\n",
       "      <td>-0.167753</td>\n",
       "      <td>0.148682</td>\n",
       "      <td>0.057840</td>\n",
       "      <td>0.164770</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10491</th>\n",
       "      <td>56790.0</td>\n",
       "      <td>1.197717</td>\n",
       "      <td>-0.651917</td>\n",
       "      <td>0.611974</td>\n",
       "      <td>-0.649222</td>\n",
       "      <td>-0.924429</td>\n",
       "      <td>-0.271165</td>\n",
       "      <td>-0.599736</td>\n",
       "      <td>0.024424</td>\n",
       "      <td>-0.873919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018038</td>\n",
       "      <td>-0.097158</td>\n",
       "      <td>0.186130</td>\n",
       "      <td>0.082522</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>-0.448918</td>\n",
       "      <td>0.036854</td>\n",
       "      <td>0.028938</td>\n",
       "      <td>59.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10492 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time         V1        V2         V3        V4         V5  \\\n",
       "0         472.0  -3.043541 -3.157307   1.088463  2.288644   1.359805   \n",
       "1       62080.0  -1.599457  2.607720  -2.987193  3.064156  -2.497914   \n",
       "2      149096.0   1.184891  3.152084  -6.134780  5.531252   1.733867   \n",
       "3       93860.0 -10.632375  7.251936 -17.681072  8.204144 -10.166591   \n",
       "4      102622.0  -2.877176  4.569649  -9.553069  4.441079  -3.653961   \n",
       "...         ...        ...       ...        ...       ...        ...   \n",
       "10487   29135.0   1.148470 -0.226385  -1.378984 -0.501250   2.115918   \n",
       "10488  161456.0   0.098372  0.881126  -0.412761 -0.501913   0.817211   \n",
       "10489   20259.0  -0.230903  0.188957   1.950648 -1.682032  -0.491241   \n",
       "10490   32140.0  -0.818437  0.592785   0.468012 -0.279240   1.401790   \n",
       "10491   56790.0   1.197717 -0.651917   0.611974 -0.649222  -0.924429   \n",
       "\n",
       "             V6         V7        V8        V9  ...       V21       V22  \\\n",
       "0     -1.064823   0.325574 -0.067794 -0.270953  ...  0.661696  0.435477   \n",
       "1     -0.541103  -2.277786  1.268166 -1.997331  ...  0.662933  0.184087   \n",
       "2     -1.816861  -0.916696  0.265568 -3.158014  ...  0.124236 -0.823865   \n",
       "3     -4.510344 -12.981606  6.783589 -4.659330  ...  2.715357  0.695603   \n",
       "4     -1.877981  -3.514353  1.547608 -2.503304  ...  1.272896  1.300268   \n",
       "...         ...        ...       ...       ...  ...       ...       ...   \n",
       "10487  3.156576  -0.191150  0.725852 -0.240172  ... -0.497682 -1.855851   \n",
       "10488 -0.925919   0.864430 -0.038913  0.142891  ... -0.346648 -0.932954   \n",
       "10489  0.442542  -0.611728 -0.566704  2.466857  ...  0.615393 -0.317370   \n",
       "10490 -1.316362   0.647986 -0.015513 -0.784337  ...  0.056923 -0.071114   \n",
       "10491 -0.271165  -0.599736  0.024424 -0.873919  ...  0.018038 -0.097158   \n",
       "\n",
       "            V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      1.375966 -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00   \n",
       "1     -0.089452 -0.506000 -0.062259 -0.052714  0.322854  0.135268  180.00   \n",
       "2     -0.079887  0.028828  0.389711  0.060171  0.485187  0.326552    0.00   \n",
       "3     -1.138122  0.459442  0.386337  0.522438 -1.416604 -0.488307  188.52   \n",
       "4     -0.003950 -0.360848 -0.597526 -0.390901  0.592197 -0.241010  346.94   \n",
       "...         ...       ...       ...       ...       ...       ...     ...   \n",
       "10487  0.146490  0.960612  0.220649 -0.123232 -0.058349  0.027293   94.31   \n",
       "10488  0.134695  0.594512 -0.465915  0.113468  0.211053  0.083482    6.45   \n",
       "10489 -0.344081 -0.355076  1.492861 -0.662246  0.117670  0.129243   11.85   \n",
       "10490 -0.134238 -0.112990 -0.167753  0.148682  0.057840  0.164770    0.76   \n",
       "10491  0.186130  0.082522  0.033200 -0.448918  0.036854  0.028938   59.87   \n",
       "\n",
       "       Class  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "10487      0  \n",
       "10488      0  \n",
       "10489      0  \n",
       "10490      0  \n",
       "10491      0  \n",
       "\n",
       "[10492 rows x 31 columns]"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('creditcard_reduced.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    10000\n",
      "1      492\n",
      "Name: count, dtype: int64\n",
      "Class\n",
      "1    492\n",
      "0    492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(['Time'], axis=1)\n",
    "print(data['Class'].value_counts())\n",
    "# Eu possuo 100 valores de classe 0 e 492 valores de classe 1. Deixando os valores iguals, 492 em cada classe\n",
    "data = data.sample(frac=1)\n",
    "fraude = data.loc[data['Class'] == 1]\n",
    "nao_fraude = data.loc[data['Class'] == 0][:492]\n",
    "normal_distributed_data = pd.concat([fraude, nao_fraude])\n",
    "print(normal_distributed_data['Class'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.457845</td>\n",
       "      <td>1.373769</td>\n",
       "      <td>-0.488926</td>\n",
       "      <td>2.805351</td>\n",
       "      <td>1.777386</td>\n",
       "      <td>0.100492</td>\n",
       "      <td>1.295016</td>\n",
       "      <td>-0.135857</td>\n",
       "      <td>-1.695822</td>\n",
       "      <td>0.955004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105593</td>\n",
       "      <td>0.371014</td>\n",
       "      <td>0.051105</td>\n",
       "      <td>0.401524</td>\n",
       "      <td>-0.724766</td>\n",
       "      <td>-0.202881</td>\n",
       "      <td>0.092124</td>\n",
       "      <td>0.094956</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-2.857170</td>\n",
       "      <td>4.045601</td>\n",
       "      <td>-4.197299</td>\n",
       "      <td>5.487199</td>\n",
       "      <td>-3.070776</td>\n",
       "      <td>-1.422686</td>\n",
       "      <td>-5.651314</td>\n",
       "      <td>2.019657</td>\n",
       "      <td>-5.015491</td>\n",
       "      <td>-6.319708</td>\n",
       "      <td>...</td>\n",
       "      <td>1.080323</td>\n",
       "      <td>-0.561384</td>\n",
       "      <td>0.102678</td>\n",
       "      <td>-0.067195</td>\n",
       "      <td>-0.476931</td>\n",
       "      <td>-0.103716</td>\n",
       "      <td>1.166961</td>\n",
       "      <td>0.663632</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>-3.896583</td>\n",
       "      <td>4.518355</td>\n",
       "      <td>-4.454027</td>\n",
       "      <td>5.547453</td>\n",
       "      <td>-4.121459</td>\n",
       "      <td>-1.163407</td>\n",
       "      <td>-6.805053</td>\n",
       "      <td>2.928356</td>\n",
       "      <td>-4.917130</td>\n",
       "      <td>-6.600461</td>\n",
       "      <td>...</td>\n",
       "      <td>1.691042</td>\n",
       "      <td>0.920021</td>\n",
       "      <td>-0.151104</td>\n",
       "      <td>0.011007</td>\n",
       "      <td>0.080303</td>\n",
       "      <td>0.412191</td>\n",
       "      <td>0.635789</td>\n",
       "      <td>0.501050</td>\n",
       "      <td>4.56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-1.662937</td>\n",
       "      <td>3.253892</td>\n",
       "      <td>-7.040485</td>\n",
       "      <td>2.266456</td>\n",
       "      <td>-4.177649</td>\n",
       "      <td>-0.746925</td>\n",
       "      <td>-0.248337</td>\n",
       "      <td>1.091157</td>\n",
       "      <td>-0.307137</td>\n",
       "      <td>-5.567947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450381</td>\n",
       "      <td>0.521162</td>\n",
       "      <td>0.308325</td>\n",
       "      <td>-0.318012</td>\n",
       "      <td>-1.255362</td>\n",
       "      <td>-0.691963</td>\n",
       "      <td>0.264878</td>\n",
       "      <td>-0.130445</td>\n",
       "      <td>600.73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>-5.222968</td>\n",
       "      <td>4.641827</td>\n",
       "      <td>-8.858204</td>\n",
       "      <td>7.723502</td>\n",
       "      <td>-1.507035</td>\n",
       "      <td>-2.159484</td>\n",
       "      <td>-4.205164</td>\n",
       "      <td>0.979334</td>\n",
       "      <td>-1.505637</td>\n",
       "      <td>-2.239066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561892</td>\n",
       "      <td>0.624207</td>\n",
       "      <td>0.536429</td>\n",
       "      <td>-0.628334</td>\n",
       "      <td>-0.222651</td>\n",
       "      <td>0.382208</td>\n",
       "      <td>-2.693036</td>\n",
       "      <td>0.407935</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10336</th>\n",
       "      <td>0.038348</td>\n",
       "      <td>-0.212700</td>\n",
       "      <td>0.857651</td>\n",
       "      <td>-1.342719</td>\n",
       "      <td>-0.561553</td>\n",
       "      <td>0.048672</td>\n",
       "      <td>0.257384</td>\n",
       "      <td>0.081733</td>\n",
       "      <td>-0.847012</td>\n",
       "      <td>0.053535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.432473</td>\n",
       "      <td>-0.881685</td>\n",
       "      <td>0.354429</td>\n",
       "      <td>-0.510900</td>\n",
       "      <td>-0.734810</td>\n",
       "      <td>-0.735214</td>\n",
       "      <td>0.097220</td>\n",
       "      <td>0.060896</td>\n",
       "      <td>94.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>-0.596335</td>\n",
       "      <td>1.025136</td>\n",
       "      <td>0.997804</td>\n",
       "      <td>2.027834</td>\n",
       "      <td>0.610285</td>\n",
       "      <td>0.884556</td>\n",
       "      <td>1.129816</td>\n",
       "      <td>-0.014741</td>\n",
       "      <td>-1.384521</td>\n",
       "      <td>0.428878</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102093</td>\n",
       "      <td>-0.295799</td>\n",
       "      <td>-0.006198</td>\n",
       "      <td>-0.941887</td>\n",
       "      <td>-0.527821</td>\n",
       "      <td>-0.123388</td>\n",
       "      <td>0.112373</td>\n",
       "      <td>0.114317</td>\n",
       "      <td>139.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2817</th>\n",
       "      <td>1.821671</td>\n",
       "      <td>-0.784809</td>\n",
       "      <td>-0.230265</td>\n",
       "      <td>0.462331</td>\n",
       "      <td>-1.009532</td>\n",
       "      <td>-0.262078</td>\n",
       "      <td>-0.792224</td>\n",
       "      <td>0.174565</td>\n",
       "      <td>1.211392</td>\n",
       "      <td>0.185305</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241528</td>\n",
       "      <td>0.696208</td>\n",
       "      <td>0.138111</td>\n",
       "      <td>0.039598</td>\n",
       "      <td>-0.407305</td>\n",
       "      <td>0.547845</td>\n",
       "      <td>-0.039506</td>\n",
       "      <td>-0.050018</td>\n",
       "      <td>64.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>-1.452766</td>\n",
       "      <td>0.714297</td>\n",
       "      <td>1.494422</td>\n",
       "      <td>1.637165</td>\n",
       "      <td>-0.770049</td>\n",
       "      <td>1.460804</td>\n",
       "      <td>-0.994385</td>\n",
       "      <td>1.519558</td>\n",
       "      <td>0.176155</td>\n",
       "      <td>-0.779515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119586</td>\n",
       "      <td>-0.275174</td>\n",
       "      <td>0.078136</td>\n",
       "      <td>-0.308839</td>\n",
       "      <td>-0.507904</td>\n",
       "      <td>-0.434369</td>\n",
       "      <td>-0.131303</td>\n",
       "      <td>-0.029504</td>\n",
       "      <td>17.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6264</th>\n",
       "      <td>0.576009</td>\n",
       "      <td>-2.657346</td>\n",
       "      <td>-1.105848</td>\n",
       "      <td>0.920221</td>\n",
       "      <td>-1.410451</td>\n",
       "      <td>-0.438924</td>\n",
       "      <td>0.327953</td>\n",
       "      <td>-0.341406</td>\n",
       "      <td>2.754593</td>\n",
       "      <td>-0.993788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516961</td>\n",
       "      <td>0.248391</td>\n",
       "      <td>-0.510540</td>\n",
       "      <td>-0.111850</td>\n",
       "      <td>-0.392685</td>\n",
       "      <td>-0.596273</td>\n",
       "      <td>-0.112439</td>\n",
       "      <td>0.085729</td>\n",
       "      <td>744.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             V1        V2        V3        V4        V5        V6        V7  \\\n",
       "390    0.457845  1.373769 -0.488926  2.805351  1.777386  0.100492  1.295016   \n",
       "147   -2.857170  4.045601 -4.197299  5.487199 -3.070776 -1.422686 -5.651314   \n",
       "266   -3.896583  4.518355 -4.454027  5.547453 -4.121459 -1.163407 -6.805053   \n",
       "62    -1.662937  3.253892 -7.040485  2.266456 -4.177649 -0.746925 -0.248337   \n",
       "383   -5.222968  4.641827 -8.858204  7.723502 -1.507035 -2.159484 -4.205164   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "10336  0.038348 -0.212700  0.857651 -1.342719 -0.561553  0.048672  0.257384   \n",
       "3141  -0.596335  1.025136  0.997804  2.027834  0.610285  0.884556  1.129816   \n",
       "2817   1.821671 -0.784809 -0.230265  0.462331 -1.009532 -0.262078 -0.792224   \n",
       "3596  -1.452766  0.714297  1.494422  1.637165 -0.770049  1.460804 -0.994385   \n",
       "6264   0.576009 -2.657346 -1.105848  0.920221 -1.410451 -0.438924  0.327953   \n",
       "\n",
       "             V8        V9       V10  ...       V21       V22       V23  \\\n",
       "390   -0.135857 -1.695822  0.955004  ...  0.105593  0.371014  0.051105   \n",
       "147    2.019657 -5.015491 -6.319708  ...  1.080323 -0.561384  0.102678   \n",
       "266    2.928356 -4.917130 -6.600461  ...  1.691042  0.920021 -0.151104   \n",
       "62     1.091157 -0.307137 -5.567947  ...  0.450381  0.521162  0.308325   \n",
       "383    0.979334 -1.505637 -2.239066  ...  0.561892  0.624207  0.536429   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "10336  0.081733 -0.847012  0.053535  ... -0.432473 -0.881685  0.354429   \n",
       "3141  -0.014741 -1.384521  0.428878  ... -0.102093 -0.295799 -0.006198   \n",
       "2817   0.174565  1.211392  0.185305  ...  0.241528  0.696208  0.138111   \n",
       "3596   1.519558  0.176155 -0.779515  ... -0.119586 -0.275174  0.078136   \n",
       "6264  -0.341406  2.754593 -0.993788  ...  0.516961  0.248391 -0.510540   \n",
       "\n",
       "            V24       V25       V26       V27       V28  Amount  Class  \n",
       "390    0.401524 -0.724766 -0.202881  0.092124  0.094956    0.00      1  \n",
       "147   -0.067195 -0.476931 -0.103716  1.166961  0.663632    1.00      1  \n",
       "266    0.011007  0.080303  0.412191  0.635789  0.501050    4.56      1  \n",
       "62    -0.318012 -1.255362 -0.691963  0.264878 -0.130445  600.73      1  \n",
       "383   -0.628334 -0.222651  0.382208 -2.693036  0.407935    1.00      1  \n",
       "...         ...       ...       ...       ...       ...     ...    ...  \n",
       "10336 -0.510900 -0.734810 -0.735214  0.097220  0.060896   94.85      0  \n",
       "3141  -0.941887 -0.527821 -0.123388  0.112373  0.114317  139.63      0  \n",
       "2817   0.039598 -0.407305  0.547845 -0.039506 -0.050018   64.99      0  \n",
       "3596  -0.308839 -0.507904 -0.434369 -0.131303 -0.029504   17.45      0  \n",
       "6264  -0.111850 -0.392685 -0.596273 -0.112439  0.085729  744.20      0  \n",
       "\n",
       "[984 rows x 30 columns]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_distributed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(normal_distributed_data.drop('Class', axis=1))\n",
    "Y = np.array(normal_distributed_data['Class'])\n",
    "RANDOM_STATE = 2\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Normalizando os dados\n",
    "X = padronizar_normal(X) # Nesse caso, utilizaremos a padronização dos dados, pois a escala dos dados é importante para o treinamento da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (629, 29)\n",
      "Y_train: (629,)\n",
      "X_val: (158, 29)\n",
      "Y_val: (158,)\n"
     ]
    }
   ],
   "source": [
    "# Separando em dados de treino, teste e validação\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "X_train, X_val, Y_train, Y_val = model_selection.train_test_split(X_train, Y_train, test_size=0.2, random_state=RANDOM_STATE)\n",
    "\n",
    "print('X_train:', X_train.shape)\n",
    "print('Y_train:', Y_train.shape)\n",
    "print('X_val:', X_val.shape)\n",
    "print('Y_val:', Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9967741935483871"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encontrando o número de neurônios na camada escondida\n",
    "num_neuronios = (X_train.shape[0] - 10)/(10*(X_train.shape[1] + 2))\n",
    "num_neuronios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bergs\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Criando a rede neural\n",
    "model = Sequential()\n",
    "# Adicionando neurônios em uma camada oculta\n",
    "model.add(Dense(2, input_dim=29, kernel_initializer='normal', activation='relu')) #quantidade de neuronios na camada escondida, nº de features\n",
    "\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid')) #camada de saída\n",
    "\n",
    "# adicionando a taxa de aprendizado\n",
    "learning_rate = 0.001  # Por exemplo, vamos definir a taxa de aprendizado como 0.001\n",
    "\n",
    "# Criando um otimizador Adam com a taxa de aprendizado desejada\n",
    "otimizador = optimizers.Adam(learning_rate=learning_rate)\n",
    "# Compilando o modelo\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = otimizador, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.5341 - loss: 0.6904 - val_accuracy: 0.5063 - val_loss: 0.6857\n",
      "Epoch 2/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5161 - loss: 0.6840 - val_accuracy: 0.5063 - val_loss: 0.6749\n",
      "Epoch 3/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5397 - loss: 0.6732 - val_accuracy: 0.8861 - val_loss: 0.6578\n",
      "Epoch 4/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8818 - loss: 0.6554 - val_accuracy: 0.8861 - val_loss: 0.6362\n",
      "Epoch 5/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8652 - loss: 0.6278 - val_accuracy: 0.8861 - val_loss: 0.6126\n",
      "Epoch 6/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8646 - loss: 0.6141 - val_accuracy: 0.8861 - val_loss: 0.5908\n",
      "Epoch 7/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8570 - loss: 0.5943 - val_accuracy: 0.8861 - val_loss: 0.5714\n",
      "Epoch 8/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8546 - loss: 0.5765 - val_accuracy: 0.8861 - val_loss: 0.5542\n",
      "Epoch 9/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8409 - loss: 0.5533 - val_accuracy: 0.8861 - val_loss: 0.5393\n",
      "Epoch 10/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8760 - loss: 0.5206 - val_accuracy: 0.8861 - val_loss: 0.5263\n",
      "Epoch 11/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8691 - loss: 0.5251 - val_accuracy: 0.8861 - val_loss: 0.5150\n",
      "Epoch 12/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8695 - loss: 0.5223 - val_accuracy: 0.8861 - val_loss: 0.5048\n",
      "Epoch 13/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8674 - loss: 0.5165 - val_accuracy: 0.8861 - val_loss: 0.4955\n",
      "Epoch 14/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8746 - loss: 0.4849 - val_accuracy: 0.8861 - val_loss: 0.4867\n",
      "Epoch 15/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8448 - loss: 0.5042 - val_accuracy: 0.8861 - val_loss: 0.4789\n",
      "Epoch 16/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8617 - loss: 0.4801 - val_accuracy: 0.8861 - val_loss: 0.4712\n",
      "Epoch 17/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8681 - loss: 0.4657 - val_accuracy: 0.8861 - val_loss: 0.4642\n",
      "Epoch 18/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8680 - loss: 0.4634 - val_accuracy: 0.8797 - val_loss: 0.4574\n",
      "Epoch 19/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8690 - loss: 0.4486 - val_accuracy: 0.8797 - val_loss: 0.4511\n",
      "Epoch 20/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8669 - loss: 0.4488 - val_accuracy: 0.8797 - val_loss: 0.4449\n",
      "Epoch 21/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8607 - loss: 0.4438 - val_accuracy: 0.8797 - val_loss: 0.4392\n",
      "Epoch 22/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8769 - loss: 0.4445 - val_accuracy: 0.8797 - val_loss: 0.4337\n",
      "Epoch 23/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8756 - loss: 0.4278 - val_accuracy: 0.8797 - val_loss: 0.4284\n",
      "Epoch 24/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8678 - loss: 0.4250 - val_accuracy: 0.8797 - val_loss: 0.4236\n",
      "Epoch 25/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8690 - loss: 0.4250 - val_accuracy: 0.8797 - val_loss: 0.4187\n",
      "Epoch 26/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8954 - loss: 0.4069 - val_accuracy: 0.8797 - val_loss: 0.4140\n",
      "Epoch 27/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.4231 - val_accuracy: 0.8797 - val_loss: 0.4094\n",
      "Epoch 28/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8899 - loss: 0.4012 - val_accuracy: 0.8797 - val_loss: 0.4050\n",
      "Epoch 29/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8859 - loss: 0.4072 - val_accuracy: 0.8797 - val_loss: 0.4009\n",
      "Epoch 30/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8880 - loss: 0.3997 - val_accuracy: 0.8797 - val_loss: 0.3968\n",
      "Epoch 31/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8884 - loss: 0.3933 - val_accuracy: 0.8797 - val_loss: 0.3929\n",
      "Epoch 32/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8874 - loss: 0.3826 - val_accuracy: 0.8797 - val_loss: 0.3890\n",
      "Epoch 33/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8767 - loss: 0.3851 - val_accuracy: 0.8797 - val_loss: 0.3854\n",
      "Epoch 34/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8684 - loss: 0.3882 - val_accuracy: 0.8797 - val_loss: 0.3818\n",
      "Epoch 35/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8850 - loss: 0.3851 - val_accuracy: 0.8797 - val_loss: 0.3783\n",
      "Epoch 36/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8683 - loss: 0.3822 - val_accuracy: 0.8797 - val_loss: 0.3751\n",
      "Epoch 37/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.3729 - val_accuracy: 0.8797 - val_loss: 0.3715\n",
      "Epoch 38/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8812 - loss: 0.3664 - val_accuracy: 0.8797 - val_loss: 0.3683\n",
      "Epoch 39/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.3718 - val_accuracy: 0.8797 - val_loss: 0.3652\n",
      "Epoch 40/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8819 - loss: 0.3795 - val_accuracy: 0.8797 - val_loss: 0.3621\n",
      "Epoch 41/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8893 - loss: 0.3573 - val_accuracy: 0.8797 - val_loss: 0.3592\n",
      "Epoch 42/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8819 - loss: 0.3603 - val_accuracy: 0.8861 - val_loss: 0.3563\n",
      "Epoch 43/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8860 - loss: 0.3631 - val_accuracy: 0.8861 - val_loss: 0.3534\n",
      "Epoch 44/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8842 - loss: 0.3468 - val_accuracy: 0.8861 - val_loss: 0.3507\n",
      "Epoch 45/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8809 - loss: 0.3509 - val_accuracy: 0.8924 - val_loss: 0.3481\n",
      "Epoch 46/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8784 - loss: 0.3422 - val_accuracy: 0.8924 - val_loss: 0.3455\n",
      "Epoch 47/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8723 - loss: 0.3581 - val_accuracy: 0.8924 - val_loss: 0.3428\n",
      "Epoch 48/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8633 - loss: 0.3626 - val_accuracy: 0.8924 - val_loss: 0.3404\n",
      "Epoch 49/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8810 - loss: 0.3580 - val_accuracy: 0.8924 - val_loss: 0.3378\n",
      "Epoch 50/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9086 - loss: 0.3259 - val_accuracy: 0.8924 - val_loss: 0.3353\n",
      "Epoch 51/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8823 - loss: 0.3439 - val_accuracy: 0.8924 - val_loss: 0.3328\n",
      "Epoch 52/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8873 - loss: 0.3235 - val_accuracy: 0.8924 - val_loss: 0.3301\n",
      "Epoch 53/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8853 - loss: 0.3333 - val_accuracy: 0.8924 - val_loss: 0.3273\n",
      "Epoch 54/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8811 - loss: 0.3351 - val_accuracy: 0.8924 - val_loss: 0.3246\n",
      "Epoch 55/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8823 - loss: 0.3361 - val_accuracy: 0.8924 - val_loss: 0.3216\n",
      "Epoch 56/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8717 - loss: 0.3410 - val_accuracy: 0.8924 - val_loss: 0.3193\n",
      "Epoch 57/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8991 - loss: 0.3225 - val_accuracy: 0.8987 - val_loss: 0.3165\n",
      "Epoch 58/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8682 - loss: 0.3495 - val_accuracy: 0.8987 - val_loss: 0.3141\n",
      "Epoch 59/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8612 - loss: 0.3473 - val_accuracy: 0.8987 - val_loss: 0.3112\n",
      "Epoch 60/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8781 - loss: 0.3268 - val_accuracy: 0.9051 - val_loss: 0.3084\n",
      "Epoch 61/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8670 - loss: 0.3353 - val_accuracy: 0.9051 - val_loss: 0.3057\n",
      "Epoch 62/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8976 - loss: 0.3109 - val_accuracy: 0.9051 - val_loss: 0.3028\n",
      "Epoch 63/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8893 - loss: 0.3099 - val_accuracy: 0.9051 - val_loss: 0.2999\n",
      "Epoch 64/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8604 - loss: 0.3478 - val_accuracy: 0.9051 - val_loss: 0.2972\n",
      "Epoch 65/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8616 - loss: 0.3388 - val_accuracy: 0.9051 - val_loss: 0.2938\n",
      "Epoch 66/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9174 - loss: 0.2891 - val_accuracy: 0.9051 - val_loss: 0.2904\n",
      "Epoch 67/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8851 - loss: 0.3235 - val_accuracy: 0.9051 - val_loss: 0.2867\n",
      "Epoch 68/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8883 - loss: 0.3150 - val_accuracy: 0.9051 - val_loss: 0.2834\n",
      "Epoch 69/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8885 - loss: 0.3121 - val_accuracy: 0.9177 - val_loss: 0.2799\n",
      "Epoch 70/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9020 - loss: 0.2857 - val_accuracy: 0.9241 - val_loss: 0.2772\n",
      "Epoch 71/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8976 - loss: 0.3022 - val_accuracy: 0.9241 - val_loss: 0.2744\n",
      "Epoch 72/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9080 - loss: 0.2986 - val_accuracy: 0.9304 - val_loss: 0.2714\n",
      "Epoch 73/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.2823 - val_accuracy: 0.9367 - val_loss: 0.2684\n",
      "Epoch 74/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2966 - val_accuracy: 0.9304 - val_loss: 0.2657\n",
      "Epoch 75/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9197 - loss: 0.2722 - val_accuracy: 0.9304 - val_loss: 0.2632\n",
      "Epoch 76/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9045 - loss: 0.2833 - val_accuracy: 0.9241 - val_loss: 0.2611\n",
      "Epoch 77/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9235 - loss: 0.2764 - val_accuracy: 0.9304 - val_loss: 0.2590\n",
      "Epoch 78/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9123 - loss: 0.2704 - val_accuracy: 0.9304 - val_loss: 0.2572\n",
      "Epoch 79/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2644 - val_accuracy: 0.9304 - val_loss: 0.2552\n",
      "Epoch 80/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9251 - loss: 0.2504 - val_accuracy: 0.9304 - val_loss: 0.2523\n",
      "Epoch 81/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9239 - loss: 0.2566 - val_accuracy: 0.9304 - val_loss: 0.2501\n",
      "Epoch 82/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9047 - loss: 0.2857 - val_accuracy: 0.9304 - val_loss: 0.2487\n",
      "Epoch 83/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2720 - val_accuracy: 0.9367 - val_loss: 0.2466\n",
      "Epoch 84/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9122 - loss: 0.2692 - val_accuracy: 0.9367 - val_loss: 0.2443\n",
      "Epoch 85/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.2554 - val_accuracy: 0.9367 - val_loss: 0.2423\n",
      "Epoch 86/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9326 - loss: 0.2415 - val_accuracy: 0.9367 - val_loss: 0.2404\n",
      "Epoch 87/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2594 - val_accuracy: 0.9367 - val_loss: 0.2389\n",
      "Epoch 88/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9267 - loss: 0.2420 - val_accuracy: 0.9367 - val_loss: 0.2373\n",
      "Epoch 89/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9114 - loss: 0.2639 - val_accuracy: 0.9367 - val_loss: 0.2356\n",
      "Epoch 90/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9281 - loss: 0.2481 - val_accuracy: 0.9367 - val_loss: 0.2341\n",
      "Epoch 91/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9345 - loss: 0.2318 - val_accuracy: 0.9367 - val_loss: 0.2331\n",
      "Epoch 92/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9319 - loss: 0.2327 - val_accuracy: 0.9367 - val_loss: 0.2319\n",
      "Epoch 93/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9290 - loss: 0.2397 - val_accuracy: 0.9367 - val_loss: 0.2301\n",
      "Epoch 94/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9331 - loss: 0.2285 - val_accuracy: 0.9367 - val_loss: 0.2288\n",
      "Epoch 95/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9243 - loss: 0.2507 - val_accuracy: 0.9430 - val_loss: 0.2271\n",
      "Epoch 96/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9137 - loss: 0.2527 - val_accuracy: 0.9367 - val_loss: 0.2269\n",
      "Epoch 97/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9241 - loss: 0.2418 - val_accuracy: 0.9430 - val_loss: 0.2252\n",
      "Epoch 98/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9390 - loss: 0.2201 - val_accuracy: 0.9430 - val_loss: 0.2240\n",
      "Epoch 99/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9353 - loss: 0.2246 - val_accuracy: 0.9430 - val_loss: 0.2228\n",
      "Epoch 100/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9327 - loss: 0.2247 - val_accuracy: 0.9430 - val_loss: 0.2218\n",
      "Epoch 101/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.2457 - val_accuracy: 0.9430 - val_loss: 0.2208\n",
      "Epoch 102/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9521 - loss: 0.2048 - val_accuracy: 0.9430 - val_loss: 0.2197\n",
      "Epoch 103/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9414 - loss: 0.2206 - val_accuracy: 0.9430 - val_loss: 0.2187\n",
      "Epoch 104/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.2348 - val_accuracy: 0.9430 - val_loss: 0.2183\n",
      "Epoch 105/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.1984 - val_accuracy: 0.9430 - val_loss: 0.2169\n",
      "Epoch 106/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9331 - loss: 0.2401 - val_accuracy: 0.9367 - val_loss: 0.2159\n",
      "Epoch 107/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9427 - loss: 0.2111 - val_accuracy: 0.9367 - val_loss: 0.2153\n",
      "Epoch 108/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9493 - loss: 0.1956 - val_accuracy: 0.9367 - val_loss: 0.2137\n",
      "Epoch 109/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.2161 - val_accuracy: 0.9304 - val_loss: 0.2134\n",
      "Epoch 110/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9480 - loss: 0.1994 - val_accuracy: 0.9304 - val_loss: 0.2124\n",
      "Epoch 111/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.1883 - val_accuracy: 0.9304 - val_loss: 0.2109\n",
      "Epoch 112/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9532 - loss: 0.1932 - val_accuracy: 0.9367 - val_loss: 0.2098\n",
      "Epoch 113/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9446 - loss: 0.2097 - val_accuracy: 0.9304 - val_loss: 0.2093\n",
      "Epoch 114/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1842 - val_accuracy: 0.9367 - val_loss: 0.2080\n",
      "Epoch 115/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.1908 - val_accuracy: 0.9304 - val_loss: 0.2076\n",
      "Epoch 116/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9304 - loss: 0.2113 - val_accuracy: 0.9304 - val_loss: 0.2072\n",
      "Epoch 117/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9504 - loss: 0.1868 - val_accuracy: 0.9304 - val_loss: 0.2060\n",
      "Epoch 118/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.1920 - val_accuracy: 0.9304 - val_loss: 0.2053\n",
      "Epoch 119/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9514 - loss: 0.1850 - val_accuracy: 0.9304 - val_loss: 0.2042\n",
      "Epoch 120/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9349 - loss: 0.2053 - val_accuracy: 0.9304 - val_loss: 0.2037\n",
      "Epoch 121/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1806 - val_accuracy: 0.9304 - val_loss: 0.2022\n",
      "Epoch 122/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9556 - loss: 0.1818 - val_accuracy: 0.9304 - val_loss: 0.2018\n",
      "Epoch 123/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.2101 - val_accuracy: 0.9304 - val_loss: 0.2012\n",
      "Epoch 124/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9447 - loss: 0.1856 - val_accuracy: 0.9241 - val_loss: 0.2001\n",
      "Epoch 125/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9431 - loss: 0.1800 - val_accuracy: 0.9241 - val_loss: 0.1992\n",
      "Epoch 126/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9497 - loss: 0.1789 - val_accuracy: 0.9241 - val_loss: 0.1990\n",
      "Epoch 127/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9576 - loss: 0.1654 - val_accuracy: 0.9177 - val_loss: 0.1984\n",
      "Epoch 128/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9483 - loss: 0.1769 - val_accuracy: 0.9177 - val_loss: 0.1977\n",
      "Epoch 129/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9450 - loss: 0.1933 - val_accuracy: 0.9241 - val_loss: 0.1958\n",
      "Epoch 130/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9615 - loss: 0.1673 - val_accuracy: 0.9241 - val_loss: 0.1944\n",
      "Epoch 131/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9444 - loss: 0.1817 - val_accuracy: 0.9177 - val_loss: 0.1958\n",
      "Epoch 132/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9515 - loss: 0.1685 - val_accuracy: 0.9241 - val_loss: 0.1952\n",
      "Epoch 133/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1613 - val_accuracy: 0.9241 - val_loss: 0.1950\n",
      "Epoch 134/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9598 - loss: 0.1579 - val_accuracy: 0.9241 - val_loss: 0.1927\n",
      "Epoch 135/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9457 - loss: 0.1809 - val_accuracy: 0.9241 - val_loss: 0.1929\n",
      "Epoch 136/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9361 - loss: 0.1877 - val_accuracy: 0.9241 - val_loss: 0.1924\n",
      "Epoch 137/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9499 - loss: 0.1673 - val_accuracy: 0.9241 - val_loss: 0.1903\n",
      "Epoch 138/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9436 - loss: 0.1815 - val_accuracy: 0.9241 - val_loss: 0.1911\n",
      "Epoch 139/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9406 - loss: 0.1779 - val_accuracy: 0.9241 - val_loss: 0.1907\n",
      "Epoch 140/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9500 - loss: 0.1681 - val_accuracy: 0.9241 - val_loss: 0.1903\n",
      "Epoch 141/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9428 - loss: 0.1655 - val_accuracy: 0.9241 - val_loss: 0.1907\n",
      "Epoch 142/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9577 - loss: 0.1501 - val_accuracy: 0.9241 - val_loss: 0.1900\n",
      "Epoch 143/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9506 - loss: 0.1560 - val_accuracy: 0.9241 - val_loss: 0.1892\n",
      "Epoch 144/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9409 - loss: 0.1736 - val_accuracy: 0.9241 - val_loss: 0.1889\n",
      "Epoch 145/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9603 - loss: 0.1481 - val_accuracy: 0.9241 - val_loss: 0.1877\n",
      "Epoch 146/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.1482 - val_accuracy: 0.9241 - val_loss: 0.1876\n",
      "Epoch 147/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9412 - loss: 0.1654 - val_accuracy: 0.9241 - val_loss: 0.1875\n",
      "Epoch 148/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9622 - loss: 0.1406 - val_accuracy: 0.9241 - val_loss: 0.1859\n",
      "Epoch 149/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.1669 - val_accuracy: 0.9241 - val_loss: 0.1870\n",
      "Epoch 150/150\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9453 - loss: 0.1621 - val_accuracy: 0.9241 - val_loss: 0.1861\n"
     ]
    }
   ],
   "source": [
    "#Treinando a rede neural\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=150, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\n",
      "--> Acuracia (treino): 0.9475\n",
      "--> Acuracia (validacao): 0.9241\n",
      "--> acc_train - acc_val = 0.0235\n",
      "--> Loss (treino): 0.1587\n",
      "--> Loss (validacao): 0.1861\n",
      "--> loss_train - loss_val = -0.0274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.0: 333, 1.0: 296}"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Metrica de erro')\n",
    "plt.ylabel('Erro')\n",
    "plt.xlabel('Epoca')\n",
    "plt.legend(['Treinamento', 'Validacao'])\n",
    "plt.show()\n",
    "\n",
    "# Obtendo a acuracia usando accuracy_score()\n",
    "pred = np.round(model.predict(X_train))\n",
    "acc_train = accuracy_score(Y_train, pred)\n",
    "\n",
    "pred_val = np.round(model.predict(X_val))\n",
    "acc_val = accuracy_score(Y_val, pred_val)\n",
    "\n",
    "print(f'\\n--> Acuracia (treino): {acc_train:.4f}')\n",
    "print(f'--> Acuracia (validacao): {acc_val:.4f}')\n",
    "print(f\"--> acc_train - acc_val = {acc_train - acc_val:.4f}\")\n",
    "print(f\"--> Loss (treino): {history.history['loss'][-1]:.4f}\")\n",
    "print(f\"--> Loss (validacao): {history.history['val_loss'][-1]:.4f}\")\n",
    "print(f\"--> loss_train - loss_val = {history.history['loss'][-1] - history.history['val_loss'][-1]:.4f}\")\n",
    "pred_np = np.array(pred)\n",
    "# encontrando os valores unicos de pred_np\n",
    "unique, counts = np.unique(pred_np, return_counts=True)\n",
    "dict(zip(unique, counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., 78.],\n",
       "       [ 1., 80.]])"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#descobrindo quantos valores unicos existem em pred_val\n",
    "valores, contagens = np.unique(pred_val, return_counts=True)\n",
    "\n",
    "# Combina os valores únicos e as contagens correspondentes\n",
    "resultados = np.column_stack((valores, contagens))\n",
    "\n",
    "resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 78],\n",
       "       [ 1, 80]], dtype=int64)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valores, contagens = np.unique(Y_val, return_counts=True)\n",
    "resultados = np.column_stack((valores, contagens))\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., 333.],\n",
       "       [  1., 296.]])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#descobrindo quantos valores unicos existem em pred\n",
    "valores, contagens = np.unique(pred, return_counts=True)\n",
    "\n",
    "# Combina os valores únicos e as contagens correspondentes\n",
    "resultados = np.column_stack((valores, contagens))\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 312],\n",
       "       [  1, 317]], dtype=int64)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valores, contagens = np.unique(Y_train, return_counts=True)\n",
    "resultados = np.column_stack((valores, contagens))\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.9461 - loss: 0.1566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.158155158162117, 0.9475357532501221]"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0s/step - accuracy: 0.9196 - loss: 0.1990  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18613959848880768, 0.9240506291389465]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
